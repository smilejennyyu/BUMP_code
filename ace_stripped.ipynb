{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import data_load\n",
    "import pandas as pd\n",
    "from src.s3_utils import pandas_from_csv_s3\n",
    "import re"
   ]
  },
  {
   "source": [
    "# Data processing: Join PHQ9, GAD7 and ACE datasets together by record_id and redcap_event_name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_load(data_keys={'phq9', 'generalized_anxiety_disorder_scale_gad7', 'ace', 'surveys', 'study_ids', 'check_in_adherence_log'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = pd.merge(data['phq9'], data['generalized_anxiety_disorder_scale_gad7'],  how='outer', left_on=['record_id','redcap_event_name'], right_on = ['record_id','redcap_event_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'outcomes' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e36bc89a30e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moverall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ace'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'redcap_event_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'record_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'outcomes' is not defined"
     ]
    }
   ],
   "source": [
    "overall_df = pd.merge(data['ace'].drop(columns=['redcap_event_name']).dropna(), outcomes, how='left', on='record_id')"
   ]
  },
  {
   "source": [
    "# Convert redcap_event_name to date for PHQ9, GAD7 and ACE datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read study ids\n",
    "id_df = data['study_ids'][['record_id', 'evidation_id']]\n",
    "id_df.rename(columns={'evidation_id': 'user_id'}, inplace=True)\n",
    "\n",
    "# add ids to survey\n",
    "overall_df = overall_df.merge(id_df, on=['record_id'])\n",
    "overall_df.user_id = overall_df.user_id.fillna(-1).astype(int)\n",
    "\n",
    "# standarize naming convention for easier processing later on\n",
    "overall_df.redcap_event_name = overall_df.redcap_event_name.replace('postnatal_checkin_arm_1','postnatal_ci_1_arm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read check-in dates\n",
    "ci_df = data['check_in_adherence_log']\n",
    "cols = ['record_id'] + [col for col in ci_df.columns if '_date' in col]\n",
    "ci_df = ci_df[cols]\n",
    "\n",
    "# standarize naming convention for easier processing later on\n",
    "ci_df = ci_df.rename(columns={'checkin_postnatal_date': 'checkin_postnatal_date_1'})\n",
    "\n",
    "# add dates to survey, need to map it using the check_in_adherence_log\n",
    "def conver_checkin_string(x):\n",
    "    x = x.split('_arm')[0] #delete all characters after the word 'arm'\n",
    "    num = int(re.search(r'\\d+', x).group())\n",
    "    if 'postnatal' in x:\n",
    "        return f'checkin_postnatal_date_{num}'\n",
    "    else:\n",
    "        return f'checkin_{num}_date'\n",
    "\n",
    "# map checkin_postnature_date_{num} OR checkin_{num}_date to the actual date\n",
    "def map_date(x):\n",
    "    checkin_string_col = x['checkin_string']\n",
    "    return x[checkin_string_col]\n",
    "\n",
    "overall_df = overall_df.merge(ci_df, on=['record_id'])\n",
    "overall_df['checkin_string'] = overall_df.redcap_event_name.apply(conver_checkin_string)\n",
    "overall_df['date'] = overall_df.apply(map_date, axis=1)\n",
    "overall_df = overall_df[overall_df.columns.drop(list(overall_df.filter(regex='checkin_')))]\n",
    "overall_df['date'] = pd.to_datetime(overall_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "overall_df.loc[overall_df['record_id'] == 28][['date', 'redcap_event_name']] #check if dates are correctly processed"
   ]
  },
  {
   "source": [
    "# Add Global survey data - PROMIS quality of life"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "promis_survey = data['surveys']\n",
    "promis_survey = promis_survey.loc[promis_survey['question_id'] == 121]\n",
    "promis_survey['date'] = pd.to_datetime(promis_survey['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['In the past 7 days:\\r\\n\\r\\nHow often have you been bothered by emotional problems such as feeling anxious, depressed or irritable?'],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "promis_survey['question_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Never', 'Rarely', 'Sometimes', 'Often', 'Always'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "promis_survey['answer_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id  user_id  survey_id          title           event_date  \\\n222517   42274       28         11  Global survey  2021-04-27 00:00:00   \n222522   70479       28         11  Global survey  2021-05-25 00:00:00   \n222559  112393       28         11  Global survey  2021-06-22 00:00:00   \n222749  497891       28         11  Global survey  2021-11-09 00:00:00   \n222800   17445       28         11  Global survey  2021-03-02 00:00:00   \n222804   24712       28         11  Global survey  2021-03-30 00:00:00   \n222825  397784       28         11  Global survey  2021-10-12 00:00:00   \n222847  170973       28         11  Global survey  2021-07-20 00:00:00   \n222910  310417       28         11  Global survey  2021-09-14 00:00:00   \n\n                       from                   to                  created_at  \\\n222517  2021-04-27 22:00:00  2021-04-28 01:00:00  2021-04-27 04:05:23.974126   \n222522  2021-05-25 22:00:00  2021-05-26 01:00:00   2021-05-25 04:05:38.04252   \n222559  2021-06-22 22:00:00  2021-06-23 01:00:00  2021-06-22 05:07:02.791691   \n222749  2021-11-09 05:00:00  2021-11-10 05:00:00  2021-11-09 05:10:22.060597   \n222800  2021-03-02 23:00:00  2021-03-03 02:00:00  2021-03-02 05:05:12.924307   \n222804  2021-03-30 22:00:00  2021-03-31 01:00:00  2021-03-30 05:05:15.752291   \n222825  2021-10-12 04:00:00  2021-10-13 04:00:00  2021-10-12 05:08:41.803388   \n222847  2021-07-20 04:00:00  2021-07-21 04:00:00  2021-07-20 05:13:18.264439   \n222910  2021-09-14 04:00:00  2021-09-15 04:00:00  2021-09-14 05:07:56.145651   \n\n                        updated_at  question_id  \\\n222517  2021-04-27 22:13:58.456141          121   \n222522  2021-05-25 22:01:50.393004          121   \n222559  2021-06-22 22:02:06.555992          121   \n222749   2021-11-09 18:39:56.79676          121   \n222800  2021-03-02 23:02:29.913693          121   \n222804   2021-03-30 22:03:08.22026          121   \n222825  2021-10-12 18:43:19.486764          121   \n222847  2021-07-20 13:29:23.240445          121   \n222910  2021-09-14 17:57:05.426492          121   \n\n                                            question_text answer_text  \\\n222517  In the past 7 days:\\r\\n\\r\\nHow often have you ...   Sometimes   \n222522  In the past 7 days:\\r\\n\\r\\nHow often have you ...   Sometimes   \n222559  In the past 7 days:\\r\\n\\r\\nHow often have you ...   Sometimes   \n222749  In the past 7 days:\\r\\n\\r\\nHow often have you ...       Often   \n222800  In the past 7 days:\\r\\n\\r\\nHow often have you ...       Often   \n222804  In the past 7 days:\\r\\n\\r\\nHow often have you ...       Often   \n222825  In the past 7 days:\\r\\n\\r\\nHow often have you ...       Often   \n222847  In the past 7 days:\\r\\n\\r\\nHow often have you ...       Often   \n222910  In the past 7 days:\\r\\n\\r\\nHow often have you ...      Always   \n\n             date  \n222517 2021-04-27  \n222522 2021-05-25  \n222559 2021-06-22  \n222749 2021-11-09  \n222800 2021-03-02  \n222804 2021-03-30  \n222825 2021-10-12  \n222847 2021-07-20  \n222910 2021-09-14  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user_id</th>\n      <th>survey_id</th>\n      <th>title</th>\n      <th>event_date</th>\n      <th>from</th>\n      <th>to</th>\n      <th>created_at</th>\n      <th>updated_at</th>\n      <th>question_id</th>\n      <th>question_text</th>\n      <th>answer_text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>222517</th>\n      <td>42274</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-04-27 00:00:00</td>\n      <td>2021-04-27 22:00:00</td>\n      <td>2021-04-28 01:00:00</td>\n      <td>2021-04-27 04:05:23.974126</td>\n      <td>2021-04-27 22:13:58.456141</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Sometimes</td>\n      <td>2021-04-27</td>\n    </tr>\n    <tr>\n      <th>222522</th>\n      <td>70479</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-05-25 00:00:00</td>\n      <td>2021-05-25 22:00:00</td>\n      <td>2021-05-26 01:00:00</td>\n      <td>2021-05-25 04:05:38.04252</td>\n      <td>2021-05-25 22:01:50.393004</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Sometimes</td>\n      <td>2021-05-25</td>\n    </tr>\n    <tr>\n      <th>222559</th>\n      <td>112393</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-06-22 00:00:00</td>\n      <td>2021-06-22 22:00:00</td>\n      <td>2021-06-23 01:00:00</td>\n      <td>2021-06-22 05:07:02.791691</td>\n      <td>2021-06-22 22:02:06.555992</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Sometimes</td>\n      <td>2021-06-22</td>\n    </tr>\n    <tr>\n      <th>222749</th>\n      <td>497891</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-11-09 00:00:00</td>\n      <td>2021-11-09 05:00:00</td>\n      <td>2021-11-10 05:00:00</td>\n      <td>2021-11-09 05:10:22.060597</td>\n      <td>2021-11-09 18:39:56.79676</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Often</td>\n      <td>2021-11-09</td>\n    </tr>\n    <tr>\n      <th>222800</th>\n      <td>17445</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-03-02 00:00:00</td>\n      <td>2021-03-02 23:00:00</td>\n      <td>2021-03-03 02:00:00</td>\n      <td>2021-03-02 05:05:12.924307</td>\n      <td>2021-03-02 23:02:29.913693</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Often</td>\n      <td>2021-03-02</td>\n    </tr>\n    <tr>\n      <th>222804</th>\n      <td>24712</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-03-30 00:00:00</td>\n      <td>2021-03-30 22:00:00</td>\n      <td>2021-03-31 01:00:00</td>\n      <td>2021-03-30 05:05:15.752291</td>\n      <td>2021-03-30 22:03:08.22026</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Often</td>\n      <td>2021-03-30</td>\n    </tr>\n    <tr>\n      <th>222825</th>\n      <td>397784</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-10-12 00:00:00</td>\n      <td>2021-10-12 04:00:00</td>\n      <td>2021-10-13 04:00:00</td>\n      <td>2021-10-12 05:08:41.803388</td>\n      <td>2021-10-12 18:43:19.486764</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Often</td>\n      <td>2021-10-12</td>\n    </tr>\n    <tr>\n      <th>222847</th>\n      <td>170973</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-07-20 00:00:00</td>\n      <td>2021-07-20 04:00:00</td>\n      <td>2021-07-21 04:00:00</td>\n      <td>2021-07-20 05:13:18.264439</td>\n      <td>2021-07-20 13:29:23.240445</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Often</td>\n      <td>2021-07-20</td>\n    </tr>\n    <tr>\n      <th>222910</th>\n      <td>310417</td>\n      <td>28</td>\n      <td>11</td>\n      <td>Global survey</td>\n      <td>2021-09-14 00:00:00</td>\n      <td>2021-09-14 04:00:00</td>\n      <td>2021-09-15 04:00:00</td>\n      <td>2021-09-14 05:07:56.145651</td>\n      <td>2021-09-14 17:57:05.426492</td>\n      <td>121</td>\n      <td>In the past 7 days:\\r\\n\\r\\nHow often have you ...</td>\n      <td>Always</td>\n      <td>2021-09-14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "promis_survey.loc[promis_survey['user_id'] == 28]"
   ]
  },
  {
   "source": [
    "# Process PHQ9, GAD and PROMIS data by taking the average over time for each individual"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # more balanced set up\n",
    "# ace_levels = {\n",
    "#     (0, 1) : 0,\n",
    "#     (2, 10): 1\n",
    "# }\n",
    "# phq9_levels = {\n",
    "#     (0, 4) : 0,\n",
    "#     (5, 9): 1,\n",
    "#     (10, 14): 1,\n",
    "#     (15, 19): 1,\n",
    "#     (20, 27): 1\n",
    "# }\n",
    "# gad_levels = {\n",
    "#     (0, 4) : 0,\n",
    "#     (5, 9): 1,\n",
    "#     (10, 14): 1,\n",
    "#     (15, 21): 1\n",
    "# }\n",
    "# promis_levels = {\n",
    "#     \"Always\" : 1,\n",
    "#     \"Often\": 1,\n",
    "#     \"Sometimes\": 1,\n",
    "#     \"Rarely\": 0,\n",
    "#     \"Never\": 0\n",
    "# }\n",
    "\n",
    "# from literature\n",
    "ace_levels = {\n",
    "    (0, 4) : 0,\n",
    "    (5, 10): 1\n",
    "}\n",
    "phq9_levels = {\n",
    "    (0, 4) : 0,\n",
    "    (5, 9): 1,\n",
    "    (10, 14): 2,\n",
    "    (15, 19): 3,\n",
    "    (20, 27): 4\n",
    "}\n",
    "gad_levels = {\n",
    "    (0, 4) : 0,\n",
    "    (5, 9): 1,\n",
    "    (10, 14): 2,\n",
    "    (15, 21): 3\n",
    "}\n",
    "promis_levels = {\n",
    "    \"Always\" : 4,\n",
    "    \"Often\": 3,\n",
    "    \"Sometimes\": 2,\n",
    "    \"Rarely\": 1,\n",
    "    \"Never\": 0\n",
    "}\n",
    "def map_levels(x, map_dict):\n",
    "    for key in map_dict:\n",
    "        if isinstance(x, str):\n",
    "            if x == key:\n",
    "                return map_dict[key]\n",
    "        else:\n",
    "            if x >= key[0] and x <= key[1]:\n",
    "                return map_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df = pd.DataFrame(columns=['user_id', 'ace_sum', 'phq9_sum', 'gad_sum', 'promis_mean'])\n",
    "for uid in overall_df['user_id'].unique():\n",
    "    each_df = overall_df.loc[overall_df['user_id']==uid]\n",
    "    ace_lst = [f'ace_{x}' for x in range(1,11)]\n",
    "    phq9_lst = [f'phq9_{x}' for x in range(1,11)]\n",
    "    gad_lst = [f'gad_{x}' for x in range(1,9)]\n",
    "    ace_sum = each_df[ace_lst].sum(axis=1)\n",
    "    ace_sum_mean = ace_sum.apply(map_levels, map_dict=ace_levels).mean()\n",
    "    phq9_sum = each_df[phq9_lst].sum(axis=1)\n",
    "    phq9_sum_mean = phq9_sum.apply(map_levels, map_dict=phq9_levels).mean()\n",
    "    gad_sum = each_df[gad_lst].sum(axis=1)\n",
    "    gad_sum_mean = gad_sum.apply(map_levels, map_dict=gad_levels).mean()\n",
    "    each_promis_df = promis_survey.loc[promis_survey['user_id']==uid]['answer_text'].apply(map_levels, map_dict=promis_levels)\n",
    "    promis_mean = each_promis_df.mean()\n",
    "    processed_overall_df = processed_overall_df.append({'user_id': uid, 'ace_sum': ace_sum_mean, 'promis_mean': promis_mean, 'phq9_sum': phq9_sum_mean, 'gad_sum': gad_sum_mean}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df = processed_overall_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_overall_df.to_csv('processed_causal_ace_4nodes_ref_levels_reverse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_overall_df[['phq9_sum', 'gad_sum', 'promis_mean']] = processed_overall_df[['phq9_sum', 'gad_sum', 'promis_mean']] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df['ace_sum'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df['phq9_sum'].round().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df['gad_sum'].round().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df['promis_mean'].round().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import notears.notears as notears\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = processed_overall_df[['ace_sum', 'phq9_sum', 'gad_sum', 'promis_mean']].to_numpy().tolist()\n",
    "output_dict = notears.run(notears.notears_standard, data, notears.loss.least_squares_loss, notears.loss.least_squares_loss_grad, e=1e-8, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acyclicity loss: {}'.format(output_dict['h']))\n",
    "print('Least squares loss: {}'.format(output_dict['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(output_dict['W'])\n",
    "plt.title(\"Learned adjacency matrix\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acyclic_W = notears.utils.threshold_output(output_dict['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(acyclic_W)\n",
    "plt.title(\"Learned adjacency matrix (thresholded)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = networkx.DiGraph(acyclic_W)\n",
    "networkx.draw(G, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_G = networkx.DiGraph((output_dict['W'] * acyclic_W).round(1))\n",
    "layout = networkx.spring_layout(weighted_G)\n",
    "networkx.draw(weighted_G, layout, node_size=1000, with_labels=True, font_weight='bold',    font_size=15)\n",
    "labels = networkx.get_edge_attributes(weighted_G,'weight')\n",
    "networkx.draw_networkx_edge_labels(weighted_G,pos=layout,edge_labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "kernelspec": {
   "name": "python361064bittestvenv12a9314f1e0742c9a94f810f33dd350e",
   "display_name": "Python 3.6.10 64-bit ('test': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}